"""
ãƒã‚±ãƒ¢ãƒ³ã‚«ãƒ¼ãƒ‰æŠ½é¸æƒ…å ±åé›†ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import json
import os
from datetime import datetime
from scrapers.nyuka_now_scraper import NyukaNowScraper
from scrapers.pokemon_center_scraper import PokemonCenterScraper
from scrapers.rakuten_books_scraper import RakutenBooksScraper
from scrapers.amazon_reservation_scraper import AmazonReservationScraper
from scrapers.rakuten_reservation_scraper import RakutenReservationScraper


def load_previous_data(filename):
    """å‰å›ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    if os.path.exists(filename):
        with open(filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None


def save_data(data, filename):
    """ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def detect_changes(old_data, new_data):
    """å¤‰æ›´ã‚’æ¤œå‡º"""
    if not old_data:
        return True, "åˆå›å®Ÿè¡Œ"

    changes = []

    # æŠ½é¸æ•°ã®å¤‰åŒ–ã‚’ãƒã‚§ãƒƒã‚¯
    old_count = len(old_data.get('lotteries', []))
    new_count = len(new_data.get('lotteries', []))

    if old_count != new_count:
        changes.append(f"æŠ½é¸æ•°ãŒå¤‰åŒ–: {old_count} â†’ {new_count}")

    # æ–°ã—ã„æŠ½é¸ã‚’ãƒã‚§ãƒƒã‚¯
    old_products = {l.get('product', '') for l in old_data.get('lotteries', [])}
    new_products = {l.get('product', '') for l in new_data.get('lotteries', [])}

    added = new_products - old_products
    if added:
        changes.append(f"æ–°è¦æŠ½é¸: {', '.join(added)}")

    removed = old_products - new_products
    if removed:
        changes.append(f"çµ‚äº†æŠ½é¸: {', '.join(removed)}")

    return len(changes) > 0, changes


def detect_reservation_changes(old_data, new_data):
    """äºˆç´„æƒ…å ±ã®å¤‰æ›´ã‚’æ¤œå‡º"""
    if not old_data:
        return True, "åˆå›å®Ÿè¡Œ"

    changes = []

    # äºˆç´„å•†å“æ•°ã®å¤‰åŒ–ã‚’ãƒã‚§ãƒƒã‚¯
    old_count = len(old_data.get('reservations', []))
    new_count = len(new_data.get('reservations', []))

    if old_count != new_count:
        changes.append(f"äºˆç´„å•†å“æ•°ãŒå¤‰åŒ–: {old_count} â†’ {new_count}")

    # æ–°ã—ã„äºˆç´„å•†å“ã‚’ãƒã‚§ãƒƒã‚¯
    old_products = {r.get('title', '') for r in old_data.get('reservations', [])}
    new_products = {r.get('title', '') for r in new_data.get('reservations', [])}

    added = new_products - old_products
    if added:
        added_list = list(added)[:3]  # æœ€å¤§3ä»¶è¡¨ç¤º
        more = len(added) - 3
        if more > 0:
            changes.append(f"æ–°è¦äºˆç´„: {', '.join(added_list)} ä»–{more}ä»¶")
        else:
            changes.append(f"æ–°è¦äºˆç´„: {', '.join(added_list)}")

    removed = old_products - new_products
    if removed:
        changes.append(f"äºˆç´„çµ‚äº†: {len(removed)}ä»¶")

    return len(changes) > 0, changes


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ãƒã‚±ãƒ¢ãƒ³ã‚«ãƒ¼ãƒ‰æŠ½é¸æƒ…å ±åé›†é–‹å§‹")
    print(f"å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    all_results = {
        'timestamp': datetime.now().isoformat(),
        'sources': []
    }

    # 1. å…¥è·Nowã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
    print("\n[1/3] å…¥è·Nowã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
    nyuka_scraper = NyukaNowScraper(check_availability=True)
    nyuka_data = nyuka_scraper.scrape()

    if nyuka_data:
        all_results['sources'].append(nyuka_data)
        print(f"âœ“ å…¥è·Now: {len(nyuka_data['lotteries'])}ä»¶ã®æŠ½é¸æƒ…å ±ã‚’å–å¾—")

        # å¤‰æ›´æ¤œå‡º
        prev_data = load_previous_data('data/nyuka_now_latest.json')
        has_changes, changes = detect_changes(prev_data, nyuka_data)
        if has_changes:
            print(f"  å¤‰æ›´æ¤œå‡º: {changes}")

        save_data(nyuka_data, 'data/nyuka_now_latest.json')
    else:
        print("âœ— å…¥è·Nowã®å–å¾—ã«å¤±æ•—")

    # 2. æ¥½å¤©ãƒ–ãƒƒã‚¯ã‚¹ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
    print("\n[2/3] æ¥½å¤©ãƒ–ãƒƒã‚¯ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
    rakuten_scraper = RakutenBooksScraper()
    rakuten_data = rakuten_scraper.scrape()

    if rakuten_data:
        all_results['sources'].append(rakuten_data)
        print(f"âœ“ æ¥½å¤©ãƒ–ãƒƒã‚¯ã‚¹: {len(rakuten_data['lotteries'])}ä»¶ã®æŠ½é¸æƒ…å ±ã‚’å–å¾—")

        # å¤‰æ›´æ¤œå‡º
        prev_data = load_previous_data('data/rakuten_books_latest.json')
        has_changes, changes = detect_changes(prev_data, rakuten_data)
        if has_changes:
            print(f"  å¤‰æ›´æ¤œå‡º: {changes}")

        save_data(rakuten_data, 'data/rakuten_books_latest.json')
    else:
        print("âœ— æ¥½å¤©ãƒ–ãƒƒã‚¯ã‚¹ã®å–å¾—ã«å¤±æ•—")

    # 3. ãƒã‚±ãƒ¢ãƒ³ã‚»ãƒ³ã‚¿ãƒ¼å…¬å¼ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
    print("\n[3/5] ãƒã‚±ãƒ¢ãƒ³ã‚»ãƒ³ã‚¿ãƒ¼å…¬å¼ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
    pokemon_center_scraper = PokemonCenterScraper()
    pokemon_center_data = pokemon_center_scraper.scrape()

    if pokemon_center_data:
        all_results['sources'].append(pokemon_center_data)
        status = "å®Ÿæ–½ä¸­" if pokemon_center_data['has_active_lottery'] else "ãªã—"
        print(f"âœ“ ãƒã‚±ãƒ¢ãƒ³ã‚»ãƒ³ã‚¿ãƒ¼å…¬å¼: æŠ½é¸{status}")

        # å¤‰æ›´æ¤œå‡º
        prev_data = load_previous_data('data/pokemon_center_latest.json')
        if prev_data and prev_data.get('has_active_lottery') != pokemon_center_data.get('has_active_lottery'):
            print(f"  âš ï¸ æŠ½é¸çŠ¶æ…‹ãŒå¤‰åŒ–ã—ã¾ã—ãŸ!")

        save_data(pokemon_center_data, 'data/pokemon_center_latest.json')
    else:
        print("âœ— ãƒã‚±ãƒ¢ãƒ³ã‚»ãƒ³ã‚¿ãƒ¼å…¬å¼ã®å–å¾—ã«å¤±æ•—")

    # 4. Amazonäºˆç´„æƒ…å ±ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
    print("\n[4/5] Amazonäºˆç´„æƒ…å ±ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
    amazon_scraper = AmazonReservationScraper()
    amazon_data = amazon_scraper.scrape()

    if amazon_data:
        all_results['sources'].append(amazon_data)
        reservation_count = len(amazon_data.get('reservations', []))
        print(f"âœ“ Amazon: {reservation_count}ä»¶ã®äºˆç´„å¯èƒ½å•†å“ã‚’å–å¾—")

        # å¤‰æ›´æ¤œå‡ºï¼ˆæ–°è¦äºˆç´„ã‚’æ¤œå‡ºï¼‰
        prev_data = load_previous_data('data/amazon_reservation_latest.json')
        has_changes, changes = detect_reservation_changes(prev_data, amazon_data)
        if has_changes:
            print(f"  å¤‰æ›´æ¤œå‡º: {changes}")

        save_data(amazon_data, 'data/amazon_reservation_latest.json')
    else:
        print("âœ— Amazonäºˆç´„æƒ…å ±ã®å–å¾—ã«å¤±æ•—")

    # 5. æ¥½å¤©ãƒ–ãƒƒã‚¯ã‚¹äºˆç´„æƒ…å ±ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
    print("\n[5/5] æ¥½å¤©ãƒ–ãƒƒã‚¯ã‚¹äºˆç´„æƒ…å ±ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
    rakuten_reservation_scraper = RakutenReservationScraper()
    rakuten_reservation_data = rakuten_reservation_scraper.scrape()

    if rakuten_reservation_data:
        all_results['sources'].append(rakuten_reservation_data)
        reservation_count = len(rakuten_reservation_data.get('reservations', []))
        print(f"âœ“ æ¥½å¤©ãƒ–ãƒƒã‚¯ã‚¹: {reservation_count}ä»¶ã®äºˆç´„å¯èƒ½å•†å“ã‚’å–å¾—")

        # å¤‰æ›´æ¤œå‡º
        prev_data = load_previous_data('data/rakuten_reservation_latest.json')
        has_changes, changes = detect_reservation_changes(prev_data, rakuten_reservation_data)
        if has_changes:
            print(f"  å¤‰æ›´æ¤œå‡º: {changes}")

        save_data(rakuten_reservation_data, 'data/rakuten_reservation_latest.json')
    else:
        print("âœ— æ¥½å¤©ãƒ–ãƒƒã‚¯ã‚¹äºˆç´„æƒ…å ±ã®å–å¾—ã«å¤±æ•—")

    # çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    save_data(all_results, 'data/all_lotteries.json')

    print("\n" + "=" * 60)
    print("åé›†å®Œäº†")
    print("=" * 60)

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    total_lotteries = sum(len(s.get('lotteries', [])) for s in all_results['sources'])
    total_reservations = sum(len(s.get('reservations', [])) for s in all_results['sources'])
    print(f"\nåˆè¨ˆ: {total_lotteries}ä»¶ã®æŠ½é¸æƒ…å ±ã€{total_reservations}ä»¶ã®äºˆç´„æƒ…å ±ã‚’åé›†")

    # Gmailé€šçŸ¥
    if os.environ.get('ENABLE_EMAIL_NOTIFICATION') == 'true':
        print("\nğŸ“§ ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ã‚’é€ä¿¡ä¸­...")
        from notify import GmailNotifier
        notifier = GmailNotifier()
        notifier.send_notification(all_results)


if __name__ == '__main__':
    main()
